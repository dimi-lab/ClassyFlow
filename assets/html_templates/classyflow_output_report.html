{% extends "base.html" %}

{% set page = "summary" %}

{% block title %}Summary - Cell Type Classification Report{% endblock %}

{% block header_title %}Cell Type Classification Report{% endblock %}
{% block header_subtitle %}Analysis Summary and Key Findings{% endblock %}

{% block content %}

<section class="page-section">
    <h2>Executive Summary</h2>
    
    <div class="alert alert-info">
        <strong>Analysis Overview:</strong> This report presents the results of automated cell type classification 
        performed on segmented mxif data using machine learning techniques. The analysis includes data normalization, 
        feature selection, model training, and comprehensive evaluation of classification performance.
    </div>

    <!-- Key Metrics Grid -->
    <div class="metrics-grid">
        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ total_cells | default("N/A") | number_format }}</div>
                <div class="metric-label">Total Cells</div>
                <div class="metric-description">Cells analyzed in the dataset</div>
                <span class="tooltiptext">
                    Total number of cells identified and segmented from the mxif data. This includes both 
                    labeled and unlabeled cells that were processed through the analysis pipeline.
                </span>
            </div>
        </div>

        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ labeled_classes | default("N/A") }}</div>
                <div class="metric-label">Labeled Classes</div>
                <div class="metric-description">Distinct cell types with labels</div>
                <span class="tooltiptext">
                    Number of distinct cell type categories that had manual annotations or labels 
                    available in the original dataset for model training.
                </span>
            </div>
        </div>

        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ training_classes | default("N/A") }}</div>
                <div class="metric-label">Training Classes</div>
                <div class="metric-description">Classes used for model training</div>
                <span class="tooltiptext">
                    Number of cell type classes that met the minimum requirements for model training 
                    (sufficient sample size, data quality, etc.) and were included in the final model.
                </span>
            </div>
        </div>

        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ normalization_method | default("N/A") }}</div>
                <div class="metric-label">Normalization Method</div>
                <div class="metric-description">Data preprocessing approach</div>
                <span class="tooltiptext">
                    The normalization technique applied to standardize the feature data before model training. 
                    Common methods include Z-score normalization, min-max scaling, or quantile normalization.
                </span>
            </div>
        </div>
    </div>

    <!-- Model Performance Metrics -->
    <h3>Model Performance</h3>
    <div class="metrics-grid">
        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ (holdout_accuracy * 100) | round(1) if holdout_accuracy else "N/A" }}%</div>
                <div class="metric-label">Holdout Accuracy</div>
                <div class="metric-description">Classification accuracy on test set</div>
                <span class="tooltiptext">
                    Percentage of correctly classified cells in the holdout test set. This metric indicates 
                    the overall performance of the model on unseen data and represents the expected accuracy 
                    for new predictions.
                </span>
            </div>
        </div>

        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ (f1_score * 100) | round(1) if f1_score else "N/A" }}%</div>
                <div class="metric-label">F1 Score</div>
                <div class="metric-description">Weighted average F1 score</div>
                <span class="tooltiptext">
                    The weighted F1 score balances precision and recall across all classes. This metric 
                    is particularly useful for datasets with imbalanced classes, providing a more 
                    comprehensive view of model performance than accuracy alone.
                </span>
            </div>
        </div>
    </div>
</section>

<!-- Classification Results -->
<section class="page-section">
    <h2>Classification Results</h2>
    
    <h3>Predicted Cell Type Distribution</h3>
    <div class="tooltip">
        <p>The following table summarizes the number of cells predicted for each cell type category:</p>
        <span class="tooltiptext">
            This table shows the distribution of predicted cell types across all cells in the dataset. 
            The counts include both originally labeled cells and newly classified unlabeled cells.
        </span>
    </div>

    <div class="table-container">
        <table>
            <thead>
                <tr>
                    <th>Cell Type</th>
                    <th>Predicted Count</th>
                    <th>Percentage</th>
                    <th>Confidence</th>
                </tr>
            </thead>
            <tbody>
                {% for cell_type in prediction_summary %}
                <tr>
                    <td>{{ cell_type.name }}</td>
                    <td>{{ cell_type.count | number_format }}</td>
                    <td>{{ (cell_type.percentage * 100) | round(1) }}%</td>
                    <td>
                        <div class="tooltip">
                            {{ (cell_type.avg_confidence * 100) | round(1) if cell_type.avg_confidence else "N/A" }}%
                            <span class="tooltiptext">
                                Average prediction confidence for this cell type. Higher values indicate 
                                more certain predictions by the model.
                            </span>
                        </div>
                    </td>
                </tr>
                {% endfor %}
            </tbody>
        </table>
    </div>
</section>

<!-- Abundance Plot -->
<section class="page-section">
    <h2>Cell Type Abundance Visualization</h2>
    
    <div class="plot-container">
        <div class="tooltip">
            <div class="plot-title">Cell Type Distribution</div>
            <span class="tooltiptext">
                This visualization shows the relative abundance of each predicted cell type in the dataset. 
                The plot helps identify dominant cell populations and rare cell types.
            </span>
        </div>
        
        {% if abundance_plot_path %}
        <img src="{{ abundance_plot_path }}" alt="Cell Type Abundance Plot" />
        {% else %}
        <div class="alert alert-warning">
            <strong>Plot not available:</strong> The abundance plot could not be generated or located. 
            Please check the pipeline output for the abundance visualization file.
        </div>
        {% endif %}
    </div>

    <div class="alert alert-info">
        <strong>Interpretation:</strong> The abundance plot provides insights into the cellular composition 
        of your sample. Dominant cell types may represent the primary tissue components, while rare populations 
        could indicate specialized cell types or contamination that may require further investigation.
    </div>
</section>

<!-- Data Quality Summary -->
<section class="page-section">
    <h2>Data Quality Assessment</h2>
    
    <div class="metrics-grid">
        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ cells_with_predictions | default("N/A") | number_format }}</div>
                <div class="metric-label">Cells with Predictions</div>
                <div class="metric-description">Successfully classified cells</div>
                <span class="tooltiptext">
                    Number of cells that received classification predictions. Cells may be excluded 
                    if they don't meet quality thresholds or have insufficient feature data.
                </span>
            </div>
        </div>

        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ (prediction_coverage * 100) | round(1) if prediction_coverage else "N/A" }}%</div>
                <div class="metric-label">Prediction Coverage</div>
                <div class="metric-description">Percentage of cells classified</div>
                <span class="tooltiptext">
                    Percentage of total cells that received classification predictions. Lower coverage 
                    may indicate data quality issues or strict filtering criteria.
                </span>
            </div>
        </div>

        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ avg_prediction_confidence | round(3) if avg_prediction_confidence else "N/A" }}</div>
                <div class="metric-label">Average Confidence</div>
                <div class="metric-description">Mean prediction confidence</div>
                <span class="tooltiptext">
                    Average confidence score across all predictions. Higher values indicate more 
                    certain classifications, while lower values may suggest ambiguous cell types 
                    or model uncertainty.
                </span>
            </div>
        </div>
    </div>
</section>

<!-- Next Steps -->
<section class="page-section">
    <h2>Next Steps</h2>
    
    <div class="alert alert-success">
        <strong>Analysis Complete:</strong> The cell type classification has been successfully completed. 
        Review the following sections for detailed information about the methodology and results:
    </div>

    <ul style="margin-left: 2rem; color: #6c757d;">
        <li><strong>Normalization Results:</strong> Details about data preprocessing and quality control measures</li>
        <li><strong>Feature Selection:</strong> Information about which features were most important for classification</li>
        <li><strong>Model Training:</strong> Comprehensive evaluation of model performance and validation results</li>
    </ul>

    <div style="margin-top: 2rem; padding: 1rem; background-color: #f8f9fa; border-radius: 6px;">
        <strong>For questions about this analysis:</strong> Contact your bioinformatics team or refer to the 
        pipeline documentation for detailed methodology and parameter settings.
    </div>
</section>

{% endblock %}

<!-- Custom Jinja2 filters that should be available in your template engine -->
{% macro number_format(value) %}
    {% if value is number %}
        {{ "{:,}".format(value) }}
    {% else %}
        {{ value }}
    {% endif %}
{% endmacro %}