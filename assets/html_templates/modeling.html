<div class="tab-content" id="modeling">

<section class="page-section">
    <h2>Model Training and Evaluation</h2>
    
    <div class="alert alert-info">
        <strong>Model Training Overview:</strong> This section presents comprehensive results from model training 
        and evaluation. The analysis includes holdout testing, class imbalance assessment, confusion matrices, 
        ROC curve analysis, and detailed performance metrics for each cell type.
    </div>

    <!-- Overall Model Performance Summary -->
    <div class="header-with-tooltip">
        <h3>Final Model Performance Summary</h3>
        <div class="tooltip-container">
            <div class="tooltip-icon">i</div>
            <div class="tooltip-popup">
                Summary of the final model's results. This is the model that is used to predict all the cell types
            </div>
        </div>
    </div>

    <div class="metrics-grid">
        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ (holdout_accuracy* 100) | round(1) if holdout_accuracy else "N/A" }}%</div>
                <div class="metric-label">Best Accuracy</div>
                <span class="tooltiptext">
                    Best overall classification accuracy achieved across all model evaluations.
                </span>
            </div>
        </div>

        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ (f1_score * 100) | round(1) if f1_score else "N/A" }}%</div>
                <div class="metric-label">Best F1 Score</div>
                <span class="tooltiptext">
                    Best weighted F1 score achieved, balancing precision and recall across all classes.
                </span>
            </div>
        </div>

        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ training_classes | default("N/A") }}</div>
                <div class="metric-label">Total Training Classes</div>
                <span class="tooltiptext">
                    Total number of cell type classes included in the final model.
                </span>
            </div>
        </div>

        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ modeling_data.best_class | default("N/A") }}</div>
                <div class="metric-label">Best Performing Class</div>
                <span class="tooltiptext">
                    The cell type with the best prediction performance based on the holdout dataset.
                </span>
            </div>
        </div>

        <div class="metric-card">
            <div class="tooltip">
                <div class="metric-value">{{ modeling_data.worst_class | default("N/A") }}</div>
                <div class="metric-label">Worst Performing Class</div>
                <span class="tooltiptext">
                    The cell type with the worst prediction performance based on the holdout dataset.
                </span>
            </div>
        </div>

    </div>
</section>

<!-- Model Comparison Summary -->
{% if modeling_data.model_comparisons %}
    <section class="page-section">
        <div class="header-with-tooltip">
            <h3>Model Comparison and Selection</h3>
            <div class="tooltip-container">
                <div class="tooltip-icon">i</div>
                <div class="tooltip-popup">
                    Results from model comparison and selection processes used to identify the best performing model.
                </div>
            </div>
        </div>

        <!-- Comparison Visualizations -->
        <div class="header-with-tooltip">
            <h5>Model Comparison Visualizations</h5>
            <div class="tooltip-container">
                <div class="tooltip-icon">i</div>
                <div class="tooltip-popup">
                    Visual comparisons of different models and their parameter optimization results.
                </div>
            </div>
        </div>

        <div style="display: flex; flex-direction: column; gap: 2rem;">
            {% if modeling_data.model_comparisons.class_distribution_plot_path %}
            <div class="plot-container">
                <div class="plot-title">Class Distribution Analysis</div>
                <img src="{{ modeling_data.model_comparisons.class_distribution_plot_path }}" alt="Class Distribution Analysis" class="embedded-image" />
                <p style="font-size: 0.9em; color: #6c757d; margin-top: 0.5rem;">
                    Analysis of class distributions used in model comparison.
                </p>
            </div>
            {% endif %}

            {% if modeling_data.model_comparisons.parameter_search_plot_path %}
            <div class="plot-container">
                <div class="plot-title">Parameter Search Results</div>
                <img src="{{ modeling_data.model_comparisons.parameter_search_plot_path }}" alt="Parameter Search" class="embedded-image" />
                <p style="font-size: 0.9em; color: #6c757d; margin-top: 0.5rem;">
                    Hyperparameter optimization results across different model configurations.
                </p>
            </div>
            {% endif %}
        </div>
        
    </section>
    {% endif %}

{% if modeling_data.holdout_evaluations %}
<!-- Model Evaluation Tabs -->
<section class="page-section">
    <div class="header-with-tooltip">
        <h3>Model Evaluation Results</h3>
        <div class="tooltip-container">
            <div class="tooltip-icon">i</div>
            <div class="tooltip-popup">
                Detailed evaluation results for each model tested. Click on the tabs below to view results for individual models.
            </div>
        </div>
    </div>

    <style>
        .model-tabs {
            display: flex;
            border-bottom: 2px solid #e9ecef;
            margin-bottom: 2rem;
            overflow-x: auto;
            flex-wrap: wrap;
        }

        .model-tab {
            padding: 0.75rem 1.5rem;
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-bottom: none;
            cursor: pointer;
            white-space: nowrap;
            transition: all 0.3s ease;
            margin-right: 2px;
            margin-bottom: 2px;
            border-radius: 6px 6px 0 0;
            min-width: 150px;
            text-align: center;
        }

        .model-tab:hover {
            background-color: #e9ecef;
        }

        .model-tab.active {
            background-color: white;
            border-bottom: 2px solid white;
            color: #667eea;
            font-weight: 600;
        }

        .model-content {
            display: none;
        }

        .model-content.active {
            display: block;
        }

        .class-performance-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 1.5rem 0;
        }

        .class-performance-card {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 6px;
            border-left: 4px solid #28a745;
            text-align: center;
        }

        .class-performance-card.poor {
            border-left-color: #dc3545;
        }

        .class-performance-card.moderate {
            border-left-color: #ffc107;
        }

        .auc-value {
            font-size: 1.8rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        .auc-value.excellent { color: #28a745; }
        .auc-value.good { color: #17a2b8; }
        .auc-value.moderate { color: #ffc107; }
        .auc-value.poor { color: #dc3545; }

        @media (max-width: 768px) {
            .model-tabs {
                flex-direction: column;
            }
            
            .model-tab {
                margin-right: 0;
                margin-bottom: 2px;
                border-radius: 6px;
                min-width: auto;
            }

            .class-performance-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>

    <!-- Model Tabs -->
    <div class="model-tabs">
        {% for model_eval in modeling_data.holdout_evaluations %}
        <div class="model-tab {% if loop.first %}active{% endif %}" 
             onclick="showModel('model-{{ loop.index0 }}')">
            {% if 'First' in model_eval.model_name %}
                First Model
            {% elif 'Second' in model_eval.model_name %}
                Second Model
            {% else %}
                "N/A"
            {% endif %}
        </div>
        {% endfor %}
    </div>

    <!-- Model Content Panels -->
    {% for model_eval in modeling_data.holdout_evaluations %}
    <div id="model-{{ loop.index0 }}" class="model-content {% if loop.first %}active{% endif %}">
        
        <!-- Model Overview -->
        <div class="header-with-tooltip">
            <h4>{{ model_eval.data.model_name }} Performance</h4>
            <div class="tooltip-container">
                <div class="tooltip-icon">i</div>
                <div class="tooltip-popup">
                    Comprehensive evaluation results for this specific model configuration.
                </div>
            </div>
        </div>

        <div class="metrics-grid">
            <div class="metric-card">
                <div class="tooltip">
                    <div class="metric-value">{{ (model_eval.data.accuracy * 100) | round(2) }}%</div>
                    <div class="metric-label">Overall Accuracy</div>
                    <span class="tooltiptext">
                        Percentage of correctly classified cells in the holdout test set.
                    </span>
                </div>
            </div>

            <div class="metric-card">
                <div class="tooltip">
                    <div class="metric-value">{{ (model_eval.data.f1_score * 100) | round(2) }}%</div>
                    <div class="metric-label">F1 Score</div>
                    <span class="tooltiptext">
                        Weighted F1 score balancing precision and recall across all classes.
                    </span>
                </div>
            </div>

            <div class="metric-card">
                <div class="tooltip">
                    <div class="metric-value">{{ model_eval.data.total_samples | number_format }}</div>
                    <div class="metric-label">Test sample size</div>
                    <span class="tooltiptext">
                        Number of cells in the holdout test set used for evaluation.
                    </span>
                </div>
            </div>
        </div>

        <!-- Class Imbalance Alert -->
        {% if model_eval.data.class_imbalance_detected %}
        <div class="alert alert-warning">
            <strong>Class Imbalance Detected:</strong> This dataset shows significant class imbalance, which may affect 
            model performance. The F1 score and per-class metrics provide more reliable performance estimates than overall accuracy.
        </div>
        {% endif %}

        {% if model_eval.data.class_names and model_eval.data.class_counts and model_eval.data.auc_scores %}
        <div class="header-with-tooltip">
            <h5>Class Performance Summary</h5>
            <div class="tooltip-container">
                <div class="tooltip-icon">i</div>
                <div class="tooltip-popup">
                    Combined view of class distribution in the test set and AUC performance for each cell type. Sorted by AUC score (highest to lowest).
                </div>
            </div>
        </div>

        <div class="table-container medium">
            <table>
                <thead>
                    <tr>
                        <th>Cell Type</th>
                        <th>Test Samples</th>
                        <th>Percentage</th>
                        <th>Class Balance</th>
                        <th>AUC Score â†“</th>
                        <th>Performance Level</th>
                    </tr>
                </thead>
                <tbody>
                    {% set total_samples = model_eval.data.class_counts | sum %}
                    
                    {# Create a list to store all class data with AUC scores #}
                    {% set class_data = [] %}
                    
                    {# Build the data structure with all class information #}
                    {% for i in range(model_eval.data.class_names | length) %}
                        {% set class_name = model_eval.data.class_names[i] %}
                        {% set count = model_eval.data.class_counts[i] %}
                        {% set percentage = (count / total_samples * 100) if total_samples > 0 else 0 %}
                        
                        {# Find matching AUC score for this class #}
                        {% set auc_score = namespace(value=0, found=false) %}
                        {% for auc_result in model_eval.data.auc_scores %}
                            {% if auc_result.class_name == class_name %}
                                {% set auc_score.value = auc_result.auc %}
                                {% set auc_score.found = true %}
                            {% endif %}
                        {% endfor %}
                        
                        {# Add to class_data list - use -1 for missing AUC to sort them last #}
                        {% set sort_value = auc_score.value if auc_score.found else -1 %}
                        {% set _ = class_data.append({
                            'name': class_name,
                            'count': count,
                            'percentage': percentage,
                            'auc_value': auc_score.value,
                            'auc_found': auc_score.found,
                            'sort_value': sort_value
                        }) %}
                    {% endfor %}
                    
                    {# Sort by AUC score descending (highest first) #}
                    {% set sorted_classes = class_data | sort(attribute='sort_value', reverse=true) %}
                    
                    {# Display sorted results #}
                    {% for class_info in sorted_classes %}
                    <tr>
                        <td><strong>{{ class_info.name }}</strong></td>
                        <td>{{ class_info.count | number_format }}</td>
                        <td>{{ "%.1f" | format(class_info.percentage) }}%</td>
                        <td>
                            <span class="badge" style="padding: 0.25rem 0.5rem; border-radius: 4px; font-size: 0.8em; font-weight: 600;
                                {% if class_info.percentage < 5 %}background-color: #f5c6cb; color: #721c24;
                                {% elif class_info.percentage < 10 %}background-color: #fff3cd; color: #856404;
                                {% elif class_info.percentage > 40 %}background-color: #d1ecf1; color: #0c5460;
                                {% else %}background-color: #d4edda; color: #155724;{% endif %}">
                                {% if class_info.percentage < 5 %}Severely Under.
                                {% elif class_info.percentage < 10 %}Underrepresented
                                {% elif class_info.percentage > 40 %}Dominant
                                {% else %}Balanced{% endif %}
                            </span>
                        </td>
                        <td>
                            {% if class_info.auc_found %}
                            <span style="font-weight: 700; font-size: 1.1em; 
                                {% if class_info.auc_value >= 0.9 %}color: #28a745;
                                {% elif class_info.auc_value >= 0.8 %}color: #17a2b8;
                                {% elif class_info.auc_value >= 0.7 %}color: #ffc107;
                                {% else %}color: #dc3545;{% endif %}">
                                {{ "%.3f" | format(class_info.auc_value) }}
                            </span>
                            {% else %}
                            <span style="color: #6c757d;">N/A</span>
                            {% endif %}
                        </td>
                        <td>
                            {% if class_info.auc_found %}
                            <span class="badge" style="padding: 0.25rem 0.5rem; border-radius: 4px; font-size: 0.8em; font-weight: 600; 
                                {% if class_info.auc_value >= 0.9 %}background-color: #d4edda; color: #155724;
                                {% elif class_info.auc_value >= 0.8 %}background-color: #d1ecf1; color: #0c5460;
                                {% elif class_info.auc_value >= 0.7 %}background-color: #fff3cd; color: #856404;
                                {% elif class_info.auc_value >= 0.6 %}background-color: #f8d7da; color: #721c24;
                                {% else %}background-color: #f5c6cb; color: #721c24;{% endif %}">
                                {% if class_info.auc_value >= 0.9 %}Excellent
                                {% elif class_info.auc_value >= 0.8 %}Good
                                {% elif class_info.auc_value >= 0.7 %}Moderate
                                {% elif class_info.auc_value >= 0.6 %}Poor
                                {% else %}Very Poor{% endif %}
                            </span>
                            {% else %}
                            <span style="color: #6c757d;">N/A</span>
                            {% endif %}
                        </td>
                    </tr>
                    {% endfor %}
                </tbody>
            </table>
        </div>

        {% endif %}

        <!-- Visualization Plots -->
        <div class="header-with-tooltip">
            <h5>Model Performance Visualizations</h5>
            <div class="tooltip-container">
                <div class="tooltip-icon">i</div>
                <div class="tooltip-popup">
                    Visual representations of model performance including confusion matrix, ROC curves, and class distributions.
                </div>
            </div>
        </div>

        <div style="display: flex; flex-direction: column; gap: 2rem;">
            {% if model_eval.data.confusion_matrix_csv_path %}
            <div class="plot-container">
                <div class="plot-title">Confusion Matrix</div>
                <img src="{{ model_eval.data.confusion_matrix_csv_path }}" alt="Confusion Matrix" class="embedded-image" />
                <p style="font-size: 0.9em; color: #6c757d; margin-top: 0.5rem;">
                    Matrix showing predicted vs. actual classifications for each cell type.
                </p>
            </div>
            {% endif %}

            {% if model_eval.data.roc_curves_plot_path %}
            <div class="plot-container">
                <div class="plot-title">ROC Curves</div>
                <img src="{{ model_eval.data.roc_curves_plot_path }}" alt="ROC Curves" class="embedded-image" />
                <p style="font-size: 0.9em; color: #6c757d; margin-top: 0.5rem;">
                    Receiver Operating Characteristic curves for each cell type classification.
                </p>
            </div>
            {% endif %}

            {% if model_eval.data.class_distribution_plot_path %}
            <div class="plot-container">
                <div class="plot-title">Class Distribution</div>
                <img src="{{ model_eval.data.class_distribution_plot_path }}" alt="Class Distribution" class="embedded-image" />
                <p style="font-size: 0.9em; color: #6c757d; margin-top: 0.5rem;">
                    Distribution of cell types in the test dataset highlighting class imbalance.
                </p>
            </div>
            {% endif %}
        </div>
    </div>
    {% endfor %}
</section>

<script>
function showModel(modelId) {
    // Hide all model content
    var contents = document.getElementsByClassName('model-content');
    for (var i = 0; i < contents.length; i++) {
        contents[i].classList.remove('active');
    }
    
    // Remove active class from all tabs
    var tabs = document.getElementsByClassName('model-tab');
    for (var i = 0; i < tabs.length; i++) {
        tabs[i].classList.remove('active');
    }
    
    // Show selected model content
    document.getElementById(modelId).classList.add('active');
    
    // Add active class to clicked tab
    event.target.classList.add('active');
}
</script>

{% else %}
<section class="page-section">
    <div class="alert alert-warning">
        <strong>No Model Training Data Available:</strong> No model evaluation results were found. This may indicate 
        that model training was not completed or the results files are missing.
    </div>
</section>
{% endif %}

</div>